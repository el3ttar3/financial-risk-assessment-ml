# -*- coding: utf-8 -*-
"""Financial_Risk_Assessment(2)_ML-Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lT9HVYhyxlB2FRD-XIDUhQYlsdB3m_Q_
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import classification_report, recall_score, roc_curve, auc, f1_score, roc_auc_score
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import Ridge
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor
from sklearn.svm import SVR
from sklearn.model_selection import GridSearchCV, cross_val_score
from sklearn.metrics import mean_absolute_error
from xgboost import XGBRegressor
from sklearn.preprocessing import PolynomialFeatures
from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

df = pd.read_csv("/content/Loan.csv")
df.head(20)

df.isnull().sum()

df.shape

duplicated = df[df.duplicated()]
duplicated

df.info()

df.describe()

df.drop('ApplicationDate', axis=1, errors='ignore', inplace=True)
df.head()

numerical_columns = df.select_dtypes(include=['number'])

plt.figure(figsize=(12, 8))
sns.boxplot(data=numerical_columns)
plt.title("Box Plot for Numerical Columns")
plt.xticks(rotation=45, ha="right")
plt.show()

numeric_features = df.select_dtypes(include=["number"])
numeric_features.columns

categorical_features = df.select_dtypes(include=["object"])
categorical_features.columns

categorical_features.head()

numeric_features.hist(bins=50, figsize=(20,15))
plt.show()

corr_matrix = numeric_features.corr()
corr_matrix["RiskScore"].sort_values(ascending=False)

#Visualize correlation
plt.subplots(figsize=(20,15))
ax = sns.heatmap(
    corr_matrix,
    vmin=-1, vmax=1, center=0,
    cmap=sns.diverging_palette(20, 220, n=200),
    square=True
)

plt.figure(figsize=(20,10))

sns.heatmap(numeric_features.corr(),cmap='BrBG',fmt='.2f',
            linewidths=2,annot=True)

def box_plot(x, y, **kwargs):
    sns.boxplot(x=x, y=y)
    x=plt.xticks(rotation=90)

#a box plot to show how the output changes with categorical features
fi = pd.melt(df, id_vars=['Age'], value_vars = categorical_features)
ga = sns.FacetGrid(fi, col="variable",  col_wrap=2, sharex=False, sharey=False)
ga = ga.map(box_plot, "value", "Age")

plt.figure(figsize=(10, 6))

# Violin plot to show distribution of RiskScore for each LoanApproved value
sns.violinplot(x='RiskScore', y='CreditScore', data=df)

# Adding titles and labels
plt.title('Relationship between Loan RiskScore and Credit Score', fontsize=16)
plt.xlabel('Risk Score', fontsize=14)
plt.ylabel('Credit Score', fontsize=14)

# Show plot
plt.show()

plt.figure(figsize=(10, 6))

# Violin plot to show distribution of Age for each LoanApproved value
sns.violinplot(x='LoanApproved', y='Age', data=df)

# Adding titles and labels
plt.title('Relationship between Loan Approval and Age', fontsize=16)
plt.xlabel('Loan Approved', fontsize=14)
plt.ylabel('Age', fontsize=14)

# Show plot
plt.show()

plt.figure(figsize=(10, 6))

# Scatterplot to show the relationship
sns.scatterplot(x='RiskScore', y='Age', data=df, hue='RiskScore', palette='coolwarm', s=100, alpha=0.6)

# Adding titles and labels
plt.title('Scatter Plot of RiskScore vs. Age', fontsize=16)
plt.xlabel('Risk Score', fontsize=14)
plt.ylabel('Age', fontsize=14)

# Show plot
plt.show()

# Initialize LabelEncoder
le = LabelEncoder()
df['EducationLevel'] = le.fit_transform(df['EducationLevel'])
df['MaritalStatus'] = le.fit_transform(df['MaritalStatus'])
df['EmploymentStatus'] = le.fit_transform(df['EmploymentStatus'])
df.head()

# One-hot encoding using pandas
df_encoded = pd.get_dummies(df, columns=['HomeOwnershipStatus', 'LoanPurpose'], drop_first=True)
df_encoded.head()

df_encoded.info()

# List of boolean columns to convert
bool_columns = [
    'HomeOwnershipStatus_Other',
    'HomeOwnershipStatus_Own',
    'HomeOwnershipStatus_Rent',
    'LoanPurpose_Debt Consolidation',
    'LoanPurpose_Education',
    'LoanPurpose_Home',
    'LoanPurpose_Other'
]

df_encoded[bool_columns] = df_encoded[bool_columns].astype(int)

df_encoded.info()

def log_transform(df_encoded, column):
    df_encoded[column] = np.log1p(df_encoded[column])  # log1p(x) is equivalent to log(1 + x), it helps avoid log(0)
    return df_encoded

for col in df_encoded.columns:
    df_encoded = log_transform(df_encoded, col)

df_encoded.head(20)

print(df['NetWorth'].max())
print(df['NetWorth'].min())

print(df_encoded['NetWorth'].max())
print(df_encoded['NetWorth'].min())

numerical_columns_2 = df_encoded.select_dtypes(include=['number'])

plt.figure(figsize=(12, 8))
sns.boxplot(data=numerical_columns_2)
plt.title("Box Plot for Numerical Columns")
plt.xticks(rotation=45, ha="right")
plt.show()

print(df_encoded['MonthlyIncome'].max())
print(df_encoded['MonthlyIncome'].min())

print(df['MonthlyIncome'].max())
print(df['MonthlyIncome'].min())

X = df_encoded.drop(columns=['RiskScore'])
Y = df_encoded['RiskScore']

X.head()

Y.head()

def engineered_features(df):
    # Creating interaction features
    df['Income_to_Loan_Ratio'] = df['AnnualIncome'] / df['LoanAmount']
    df['Debt_to_Assets_Ratio'] = df['TotalLiabilities'] / df['TotalAssets']
    df['Monthly_Income_to_Payment_Ratio'] = df['MonthlyIncome'] / df['MonthlyLoanPayment']

    poly = PolynomialFeatures(degree=2, include_bias=False)
    poly_features = poly.fit_transform(df[['CreditScore', 'DebtToIncomeRatio']])
    df['CreditScore_Squared'] = poly_features[:, -2]
    df['DTI_Squared'] = poly_features[:, -1]

    return df

X = engineered_features(X)

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

X_train.shape

y_train.shape

models = {
    'SVR_Linear': {
        'model': Pipeline([
            ('scaler', StandardScaler()),
            ('svr', SVR(kernel='linear'))
        ]),
        'params': {
            'svr__C': [0.1],
            'svr__epsilon': [0.1]
        }
    },
    'SVR_RBF': {
        'model': Pipeline([
            ('scaler', StandardScaler()),
            ('svr', SVR(kernel='rbf'))
        ]),
        'params': {
            'svr__C': [0.1],
            'svr__gamma': ['auto', 0.1],
            'svr__epsilon': [0.1]
        }
    },
    'RandomForest': {
        'model': RandomForestRegressor(),
        'params': {
            'n_estimators': [100, 200],
            'max_depth': [10, 20],
            'min_samples_split': [2, 5]
        }
    },
    'GradientBoosting': {
        'model': GradientBoostingRegressor(),
        'params': {
            'n_estimators': [100, 200],
            'max_depth': [3, 5],
            'learning_rate': [0.01, 0.1]
        }
    }
}

def evaluate_model(y_true, y_pred, model_name):
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)

    return {
        'Model': model_name,
        'MSE': mse,
        'RMSE': rmse,
        'MAE': mae,
        'RÂ²': r2
    }

def train_best_model(X_train, y_train, models):
    best_mse = float('inf')
    best_model = None
    best_model_name = None
    results = []

    for model_name, model_info in models.items():
        print(f"\nTraining {model_name}...")

        # Performing GridSearchCV with cross-validation
        grid_search = GridSearchCV(
            model_info['model'],
            model_info['params'],
            cv=5,
            scoring='r2',
            n_jobs=-1,
            verbose=1
        )

        grid_search.fit(X_train, y_train)

        # Calculate MSE on training data
        y_pred = grid_search.predict(X_train)
        current_mse = mean_squared_error(y_train, y_pred)

        if current_mse < best_mse:
            best_mse = current_mse
            best_model = grid_search.best_estimator_
            best_model_name = model_name

        # # Evaluate model
        # model_results = evaluate_model(y_test, y_pred, model_name)
        # results.append(model_results)

        print(f"Best parameters for {model_name}: {grid_search.best_params_}")
        print(f"MSE Score: {current_mse:.4f}")

    print(f"\nBest performing model: {best_model_name}")
    print(f"Best MSE score: {best_mse:.4f}")

    return best_model

def predict_on_new_data(best_model, X_test_new):
    predictions = best_model.predict(X_test_new)
    return predictions

train_best_model(X_train,y_train,models)

test_df = pd.read_csv("/content/Regression_test_file.csv")
loan_df =pd.read_csv("/content/Loan.csv")

loan_df.drop('RiskScore', axis=1 ,inplace= True)

loan_columns = loan_df.columns.tolist()

# Reorder test_df columns to match loan_df
test_df = test_df[loan_columns]

test_df.to_csv('Regression_test_file_reordered.csv', index=False)

# Print validation
print("Original Loan.csv columns:")
print(loan_df.columns.tolist())
print("\nReordered Test file columns:")
print(test_df.columns.tolist())
print("\nColumns are identical:", loan_df.columns.tolist() == test_df.columns.tolist())

df_testing = pd.read_csv("/content/Regression_test_file_reordered.csv")
df_testing.drop('ApplicationDate', axis=1, errors='ignore', inplace=True)

df_testing.drop('RiskScore', axis=1, errors='ignore', inplace=True)

df_testing['EducationLevel'] = le.fit_transform(df_testing['EducationLevel'])
df_testing['MaritalStatus'] = le.fit_transform(df_testing['MaritalStatus'])
df_testing['EmploymentStatus'] = le.fit_transform(df_testing['EmploymentStatus'])
df_encoded2 = pd.get_dummies(df_testing, columns=['HomeOwnershipStatus', 'LoanPurpose'], drop_first=True)
df_encoded2.info()

df_encoded2[bool_columns] = df_encoded2[bool_columns].astype(int)
for col2 in df_encoded2.columns:
    df_encoded2 = log_transform(df_encoded2, col2)

X2 = df_encoded2

X2 = engineered_features(X2)

best_model = train_best_model(X_train,y_train,models)

predictions = predict_on_new_data(best_model, X2)

submission = pd.DataFrame({
    'ID': range(len(predictions)),
    'Prediction': predictions
})

submission.to_csv('submission.csv', index=False)

results_df.head()